{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy %': 97.9, 'TP': 490, 'TN': 71, 'FP': 3, 'FN': 9, 'recall %': 98.2, 'precision %': 99.4, 'F1_Score %': 98.8}\n"
     ]
    }
   ],
   "source": [
    "# import Necessary things \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Sample data\n",
    "with open(\"file.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    messages = []\n",
    "    test_data=[]\n",
    "    for line in lines[:5001]:\n",
    "        # Strip whitespace and split on the first tab character\n",
    "        level, sentence = line.strip().split('\\t', 1)\n",
    "        messages.append((sentence, level))\n",
    "    for line in lines[5001:]:\n",
    "        level, sentence = line.strip().split('\\t', 1)\n",
    "        test_data.append((sentence, level))\n",
    "\n",
    "# Load NLTK stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Step 1: Tokenize words using NLTK\n",
    "def tokenize(text):\n",
    "    lst=[]\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        if word.isalnum() and word not in stop_words:\n",
    "            lst.append(word)\n",
    "    return lst\n",
    "\n",
    "# Step 2: Count word frequencies\n",
    "def count_words(messages):\n",
    "    spam_words = {}\n",
    "    ham_words = {}\n",
    "    spam_count = 0\n",
    "    ham_count = 0\n",
    "\n",
    "    for message, label in messages:\n",
    "        words = tokenize(message)\n",
    "        if label == \"spam\":\n",
    "            spam_count += 1\n",
    "            for word in words:\n",
    "                if word not in spam_words:\n",
    "                    spam_words[word] = 0\n",
    "                spam_words[word] += 1\n",
    "        else:\n",
    "            ham_count += 1\n",
    "            for word in words:\n",
    "                if word not in ham_words:\n",
    "                    ham_words[word] = 0\n",
    "                ham_words[word] += 1\n",
    "\n",
    "    return spam_words, ham_words, spam_count, ham_count\n",
    "\n",
    "# Step 3: Calculate probabilities\n",
    "def calculate_probabilities(spam_words, ham_words, spam_count, ham_count):\n",
    "    total_spam_words = sum(spam_words.values())\n",
    "    total_ham_words = sum(ham_words.values())\n",
    "    \n",
    "    # Total number of messages\n",
    "    total_messages = spam_count + ham_count\n",
    "    \n",
    "    # P(spam) and P(ham)\n",
    "    p_spam = spam_count / total_messages\n",
    "    p_ham = ham_count / total_messages\n",
    "    \n",
    "    return total_spam_words, total_ham_words, p_spam, p_ham\n",
    "\n",
    "# Step 4: Naive Bayes Classification with Laplace Smoothing\n",
    "def classify(message, spam_words, ham_words, total_spam_words, total_ham_words, p_spam, p_ham):\n",
    "    words = tokenize(message)\n",
    "    \n",
    "    # Initialize probabilities with prior probabilities\n",
    "    spam_prob = p_spam\n",
    "    ham_prob = p_ham\n",
    "    \n",
    "    # Laplace smoothing constant\n",
    "    smoothing = 1.0\n",
    "    \n",
    "    # Total unique words for Laplace smoothing\n",
    "    vocab_size = len(set(spam_words.keys()).union(set(ham_words.keys())))\n",
    "    \n",
    "    # Calculate the probability of each word being in spam or ham\n",
    "    for word in words:\n",
    "        # Calculate spam word probability with smoothing\n",
    "        spam_word_freq = spam_words.get(word, 0) + smoothing\n",
    "        spam_prob *= spam_word_freq / (total_spam_words + vocab_size * smoothing)\n",
    "        \n",
    "        # Calculate ham word probability with smoothing\n",
    "        ham_word_freq = ham_words.get(word, 0) + smoothing\n",
    "        ham_prob *= ham_word_freq / (total_ham_words + vocab_size * smoothing)\n",
    "    \n",
    "    # Classify based on the final probabilities\n",
    "    return 1 if ham_prob > spam_prob else 0  # Return 1 for ham, 0 for spam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training the classifier\n",
    "spam_words, ham_words, spam_count, ham_count = count_words(messages)\n",
    "total_spam_words, total_ham_words, p_spam, p_ham = calculate_probabilities(spam_words, ham_words, spam_count, ham_count)\n",
    "\n",
    "# test a new message from test data\n",
    "# matrix have lists having actual value and predicted value\n",
    "matrix=[]\n",
    "for mess,level in test_data:\n",
    "    if level=='ham':\n",
    "        classification = classify(mess, spam_words, ham_words, total_spam_words, total_ham_words, p_spam, p_ham)\n",
    "        if classification==1:\n",
    "            matrix.append([1,1])\n",
    "        else:\n",
    "            matrix.append([1,0])\n",
    "    if level=='spam':\n",
    "        classification = classify(mess, spam_words, ham_words, total_spam_words, total_ham_words, p_spam, p_ham)\n",
    "        if classification==1:\n",
    "            matrix.append([0,1])\n",
    "        else:\n",
    "            matrix.append([0,0])\n",
    "\n",
    "# Decision Making points about the modal\n",
    "def getAnalyticsOfTest(matrix):\n",
    "    \n",
    "    TP_count=0\n",
    "    TN_count=0\n",
    "    FP_count=0\n",
    "    FN_count=0\n",
    "\n",
    "    #n=len(matrix)\n",
    "    for i in matrix:\n",
    "        if i[0]==1 and i[1]==1:\n",
    "            TP_count+=1\n",
    "        if i[0]==1 and i[1]==0:\n",
    "            FN_count+=1\n",
    "        if i[0]==0 and i[1]==1:\n",
    "            FP_count+=1\n",
    "        if i[0]==0 and i[1]==0:\n",
    "            TN_count+=1\n",
    "    accuracy = round((TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)*100, 1) \n",
    "    recall = TP_count / (TP_count + FN_count)\n",
    "    recall=round((recall*100),1)\n",
    "    precision = round((TP_count / (TP_count + FP_count))*100, 1)\n",
    "    F1_score = round((2 * recall * precision) / (recall + precision), 1)  # No additional * 100 here\n",
    "\n",
    "\n",
    "    return ({\"Accuracy %\":accuracy,\"TP\":TP_count,\"TN\":TN_count,\"FP\":FP_count,\"FN\":FN_count,\"recall %\":recall,\"precision %\":precision,\"F1_Score %\":F1_score})\n",
    "\n",
    "print(getAnalyticsOfTest(matrix)) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
